{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 网络结构设计\n",
    "1. 提取用户特征和电影特征作为网络的输入，其中：\n",
    "    - 用户特征包含：性别、年龄和职业\n",
    "    - 电影特征包含：电影名称、电影类型以及电影海报\n",
    "2. 提取用户信息，使用Embedding层将用户特征映射为向量表示，然后输入到全连接层并相加\n",
    "3. 提取电影信息，将电影类型映射为向量表示，电影名称和电影海报使用卷积层得到向量表示，然后输入到全连接层并相加\n",
    "4. 得到用户和电影的向量表示后，计算二者的余弦相似度。最后，用该相似度和用户真实评分的均方差作为该回归模型的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 用户信息\n",
    "### 1.1 提取性别特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "tensor([[0.0000, 0.5396, 0.3582, 0.0000, 0.0000, 0.8593, 0.8885, 0.0000, 0.6045,\n",
      "         0.4596, 0.0000, 0.0000, 0.3659, 0.0000, 0.5746, 0.2763],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2292, 0.0000, 0.0000, 0.5469, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.1382, 0.0000, 1.1761, 0.4018, 1.2456]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 自定义一个用户性别数据\n",
    "usr_gender_data = np.array((0, 1)).reshape(-1).astype('int64')\n",
    "usr_gender_dict_size = 2\n",
    "usr_gender_emb = nn.Embedding(num_embeddings=usr_gender_dict_size, embedding_dim=16)\n",
    "usr_gender_fc = nn.Linear(in_features=16, out_features=16)\n",
    "\n",
    "usr_gender_var = torch.from_numpy(usr_gender_data)\n",
    "usr_gender_feat = usr_gender_fc(usr_gender_emb(usr_gender_var))\n",
    "usr_gender_feat = F.relu(usr_gender_feat)\n",
    "print(usr_gender_feat.shape)\n",
    "print(usr_gender_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 提取用户年龄特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "tensor([[0.0000, 0.0000, 0.2369, 0.0000, 0.0000, 1.3198, 0.6582, 0.0000, 0.1871,\n",
      "         0.3894, 0.1162, 0.0000, 0.0282, 0.0000, 0.2151, 1.2145],\n",
      "        [0.0000, 0.0000, 0.9539, 0.0000, 1.0452, 0.5438, 0.7035, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.1451]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 自定义一个用户年龄数据\n",
    "usr_age_data = np.array((1, 18)).reshape(-1).astype('int64')\n",
    "usr_age_dict_size = 56 + 1\n",
    "usr_age_emb = nn.Embedding(num_embeddings=usr_age_dict_size, embedding_dim=16)\n",
    "usr_age_fc = nn.Linear(in_features=16, out_features=16)\n",
    "\n",
    "usr_age_var = torch.from_numpy(usr_age_data)\n",
    "usr_age_feat = usr_age_fc(usr_age_emb(usr_age_var))\n",
    "usr_age_feat = F.relu(usr_age_feat)\n",
    "print(usr_age_feat.shape)\n",
    "print(usr_age_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 提取用户职业特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "tensor([[0.2584, 0.0000, 0.0359, 0.0000, 0.0000, 0.3537, 0.0000, 0.1387, 0.0361,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0245, 0.0305, 0.0000],\n",
      "        [0.2721, 0.7482, 0.4157, 0.3370, 0.1461, 0.8518, 0.8119, 0.0000, 0.3327,\n",
      "         0.0000, 0.0361, 0.5232, 0.0000, 0.0000, 0.0000, 0.6352]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "usr_job_data = np.array((0, 20)).reshape(-1).astype('int64')\n",
    "usr_job_dict_size = 20 + 1\n",
    "usr_job_emb = nn.Embedding(num_embeddings=usr_job_dict_size, embedding_dim=16)\n",
    "usr_job_fc = nn.Linear(in_features=16, out_features=16)\n",
    "\n",
    "usr_job_var = torch.from_numpy(usr_job_data)\n",
    "usr_job_feat = usr_job_fc(usr_job_emb(usr_job_var))\n",
    "usr_job_feat = F.relu(usr_job_feat)\n",
    "print(usr_job_feat.shape)\n",
    "print(usr_job_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 融合用户特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200])\n",
      "tensor([[-5.1335e-01, -1.5911e-01, -2.0008e-01, -1.5151e-02,  3.7745e-01,\n",
      "         -3.5872e-01, -4.1245e-01,  4.1987e-01, -3.6836e-01,  1.6747e-01,\n",
      "          3.5504e-01, -1.1205e-01, -5.4380e-03,  3.1931e-01, -4.7137e-01,\n",
      "         -6.2006e-02,  7.3392e-01, -1.6450e-02, -1.8560e-01,  2.6359e-01,\n",
      "          3.0754e-01, -2.2211e-02,  1.8506e-01, -3.9725e-01, -3.3545e-01,\n",
      "          2.7002e-01, -1.3147e-01, -1.6463e-01,  1.4269e-01, -3.1910e-01,\n",
      "         -6.6017e-01, -2.4616e-01, -8.8197e-02,  2.6558e-01,  6.8087e-01,\n",
      "          7.1073e-01,  5.6292e-01, -2.9444e-01, -4.2485e-01, -2.1698e-01,\n",
      "          4.4503e-01, -1.8938e-02,  2.9185e-01, -6.5213e-01,  5.4178e-01,\n",
      "         -3.8499e-01,  5.7499e-01,  1.8843e-01, -7.4801e-02, -5.3716e-01,\n",
      "          4.7628e-01, -5.3107e-01,  9.3963e-02,  3.7328e-01,  5.6909e-02,\n",
      "          9.2058e-01,  3.5076e-01, -2.4744e-01,  5.4148e-01, -1.6832e-01,\n",
      "         -8.3651e-02,  1.4196e-01, -5.2339e-01, -3.8508e-01, -5.5372e-01,\n",
      "          5.6065e-01,  4.0749e-01,  2.0722e-01, -5.1961e-01,  1.7468e-01,\n",
      "          1.1701e-01, -2.3305e-01, -3.6361e-04,  5.6075e-01,  3.2570e-02,\n",
      "          5.8835e-01,  1.8351e-01, -2.5852e-01,  2.4873e-01, -3.6606e-01,\n",
      "         -1.5192e-01,  1.1829e-01,  1.0316e+00,  2.4745e-01, -1.0021e-01,\n",
      "         -5.9838e-01, -1.7091e-01,  1.5780e-01,  3.7735e-02, -4.2317e-01,\n",
      "         -1.2926e-01, -3.1960e-01, -4.6255e-01,  7.0821e-02,  8.3615e-02,\n",
      "         -5.2164e-01,  2.4621e-02,  5.0976e-01, -1.0662e-02, -1.1853e-01,\n",
      "          5.2537e-01, -7.8842e-01, -4.0240e-01, -2.7228e-01,  3.1089e-01,\n",
      "          4.5545e-01,  1.7476e-01,  4.6903e-01,  1.5542e-01,  3.9189e-02,\n",
      "          6.1366e-01, -4.5104e-01,  1.0446e-02,  5.9769e-02, -7.7796e-02,\n",
      "          1.7010e-01, -4.8577e-02,  2.5103e-01,  2.8671e-01, -5.7742e-02,\n",
      "          3.4229e-01, -2.2718e-01, -1.8142e-01, -5.8126e-01, -4.8209e-01,\n",
      "         -7.0869e-01, -1.3202e-02,  5.1599e-01,  1.3226e-01, -9.8421e-02,\n",
      "          2.1906e-01,  2.3727e-01, -5.1943e-01,  3.9599e-02,  2.2609e-01,\n",
      "         -2.0705e-01, -1.9110e-02, -1.1541e-01,  3.7934e-01, -1.0756e-01,\n",
      "          4.6370e-01,  1.8153e-01, -4.9224e-02, -1.4538e-01, -6.2353e-01,\n",
      "          6.6918e-02, -3.7186e-01, -1.0664e+00, -4.8888e-02,  1.4729e-01,\n",
      "          8.2933e-02,  2.5009e-01,  1.0829e-01,  2.1401e-01,  2.2583e-02,\n",
      "         -2.9415e-01, -3.1372e-01, -4.8662e-01,  2.0006e-01,  1.5898e-01,\n",
      "          1.0082e-01,  1.6220e-01,  6.0226e-01,  4.4003e-01, -2.0844e-01,\n",
      "         -4.7590e-01, -7.6848e-02,  1.3238e+00, -1.8247e-02, -2.7188e-01,\n",
      "          5.6426e-01, -7.9334e-01, -1.2938e-01, -4.6003e-01, -6.8120e-01,\n",
      "         -2.5011e-01,  2.2978e-01, -4.0690e-01, -5.9306e-01, -4.8992e-02,\n",
      "         -1.3545e-01, -1.4819e-01, -7.1245e-01, -2.5236e-01, -4.0100e-01,\n",
      "         -4.7144e-02,  4.0824e-01, -4.3073e-01,  2.5253e-01, -6.7110e-01,\n",
      "          3.7632e-02,  9.3970e-02,  3.9097e-01,  1.5033e-01, -4.6318e-01,\n",
      "          5.7411e-01, -2.8038e-01,  1.8617e-01, -1.1727e-01, -1.4632e-01],\n",
      "        [-2.2928e-01,  4.8833e-01, -5.7177e-01, -4.2624e-01, -2.0077e-01,\n",
      "         -5.5032e-01, -7.3749e-01,  1.3406e-01, -2.7310e-01,  5.9715e-01,\n",
      "          3.6034e-01, -3.5701e-01, -7.9394e-01,  6.3233e-01, -1.5498e-01,\n",
      "          1.5344e-01, -8.1698e-02,  3.0897e-01,  1.0652e-01, -5.2178e-01,\n",
      "         -2.9959e-02,  3.3670e-02,  1.3690e-01, -7.1374e-02, -3.5580e-01,\n",
      "          2.5620e-01, -6.1581e-01,  3.0112e-01,  6.1267e-03, -3.5713e-01,\n",
      "         -3.5480e-01,  1.9842e-02, -3.2400e-02,  1.8480e-01,  5.0061e-01,\n",
      "          9.0418e-01,  4.3570e-01, -1.6211e-01, -1.4873e-01,  5.7924e-01,\n",
      "          4.3002e-01, -1.9943e-01,  8.1580e-01,  7.3295e-02,  6.1309e-01,\n",
      "         -1.1491e+00,  2.4330e-02, -7.2158e-02, -8.1153e-01, -1.3512e+00,\n",
      "          1.0123e+00, -5.2401e-01,  4.4328e-01,  5.6287e-01,  6.1495e-01,\n",
      "          1.0201e+00, -3.2218e-01, -6.8192e-02,  2.6148e-01,  2.7003e-01,\n",
      "          1.9861e-02,  2.5435e-01, -3.0938e-01, -4.6750e-01, -1.3232e+00,\n",
      "          5.6395e-01,  3.6703e-01,  3.5679e-01, -6.8631e-01,  1.1337e-01,\n",
      "         -1.9112e-02, -1.9735e-01,  3.7902e-01, -4.8147e-01,  4.1150e-03,\n",
      "          3.9101e-01, -3.0873e-02, -9.3949e-03,  1.8028e-01, -5.0607e-01,\n",
      "         -7.2607e-01, -2.8681e-01,  2.3936e-01,  8.9374e-01,  1.3387e-01,\n",
      "         -5.6983e-01,  3.6024e-01,  2.0352e-01,  4.1139e-01,  2.4331e-01,\n",
      "         -3.8998e-01, -8.1120e-01, -1.6910e-01,  1.2096e-01, -1.5722e-01,\n",
      "         -1.4102e+00, -6.4371e-01,  8.0711e-01,  6.6355e-01, -2.9191e-01,\n",
      "          8.4491e-01, -1.2744e+00, -3.0890e-01, -7.0959e-01, -2.0745e-01,\n",
      "          3.8457e-02,  5.6219e-01,  2.9845e-01,  1.8125e-01,  1.6201e-01,\n",
      "          6.5911e-01, -3.3367e-01,  3.0537e-01,  6.6130e-02,  2.5093e-01,\n",
      "         -4.2613e-01, -9.3174e-02,  9.7355e-01,  5.2060e-01,  1.9850e-01,\n",
      "          4.3145e-01,  3.8698e-01, -8.0396e-01, -1.2110e+00, -8.3878e-01,\n",
      "         -4.3362e-01,  9.4872e-02, -1.3150e-01,  2.2791e-01, -1.8622e-02,\n",
      "          4.6052e-01, -7.9829e-01, -3.9919e-01,  1.9746e-01,  2.3456e-01,\n",
      "          1.9153e-01,  7.6328e-01, -4.3406e-01,  1.1738e-01, -2.9805e-01,\n",
      "          5.5538e-01, -5.6929e-02,  2.1109e-01,  3.3930e-01, -3.7637e-01,\n",
      "         -7.9832e-01, -8.6855e-01, -1.0017e+00,  7.3318e-01,  1.7990e-01,\n",
      "          6.6440e-02, -5.9560e-01,  4.4739e-02, -7.5365e-02, -2.8123e-01,\n",
      "         -5.8727e-01, -3.9560e-01,  2.9134e-01,  5.2803e-01,  1.9054e-01,\n",
      "          6.1940e-04,  7.7303e-01,  6.4668e-01,  6.2887e-02,  7.4800e-01,\n",
      "         -7.6421e-02,  2.1431e-01,  8.8669e-01, -5.6139e-02,  3.3475e-01,\n",
      "          8.2380e-01, -2.2028e-01,  2.2783e-01, -8.7839e-01, -3.2301e-01,\n",
      "          8.9696e-04,  1.2918e-01, -3.4065e-01, -7.4940e-01, -4.4166e-01,\n",
      "         -3.7031e-01,  6.7894e-02, -3.3474e-01, -8.7783e-01, -8.8475e-03,\n",
      "          3.3495e-02,  2.4567e-01, -6.7032e-02,  1.6098e-01, -1.3178e-01,\n",
      "          7.5423e-03,  7.7976e-01,  8.5651e-01, -3.8106e-01, -1.0338e+00,\n",
      "          5.5261e-02,  2.7449e-01, -5.8405e-01, -5.3273e-01,  1.6101e-01]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlz/miniconda3/envs/rs/lib/python3.7/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "fc_job = nn.Linear(in_features=16, out_features=200)\n",
    "fc_age = nn.Linear(in_features=16, out_features=200)\n",
    "fc_gender = nn.Linear(in_features=16, out_features=200)\n",
    "\n",
    "gender_feat = F.tanh(fc_gender(usr_gender_feat))\n",
    "age_feat = F.tanh(fc_age(usr_age_feat))\n",
    "job_feat = F.tanh(fc_job(usr_job_feat))\n",
    "\n",
    "usr_feat = gender_feat + age_feat + job_feat\n",
    "print(usr_feat.shape)\n",
    "print(usr_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 电影特征提取\n",
    "### 2.1 提取电影类别特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32])\n",
      "tensor([[3.5934, 0.0000, 1.8565, 1.7676, 3.7018, 0.5713, 0.5355, 0.9211, 0.0000,\n",
      "         0.0000, 0.8788, 0.0000, 0.0000, 0.0000, 0.1978, 4.8158, 2.4074, 1.7421,\n",
      "         0.0000, 2.7812, 0.5020, 0.0000, 1.3836, 0.0000, 4.1446, 0.6200, 0.0612,\n",
      "         0.0000, 0.0000, 6.7134, 1.0453, 2.6819],\n",
      "        [2.8123, 0.0000, 3.0742, 1.2698, 3.1001, 0.1666, 0.0000, 0.6157, 0.0000,\n",
      "         0.0000, 1.1570, 0.0146, 0.0000, 0.0000, 0.0000, 4.8261, 1.3017, 0.7606,\n",
      "         0.0000, 3.1402, 0.0326, 0.0000, 1.3067, 0.0000, 3.7382, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 5.4824, 1.5428, 1.0031]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 自定义电影类别数据\n",
    "mov_cat_data = np.array([[1, 2, 3, 0, 0, 0], [2, 3, 4, 0, 0, 0]]).reshape(2, -1).astype('int64')\n",
    "mov_cat_dict_size = 18 + 1\n",
    "mov_cat_emb = nn.Embedding(num_embeddings=mov_cat_dict_size, embedding_dim=32)\n",
    "mov_cat_fc = nn.Linear(in_features=32, out_features=32)\n",
    "\n",
    "mov_cat_var = torch.from_numpy(mov_cat_data)\n",
    "mov_cat_feat = mov_cat_emb(mov_cat_var)\n",
    "\n",
    "# 沿着类别数量维度进行求和\n",
    "mov_cat_feat = torch.sum(mov_cat_feat, dim=1, keepdim=False)\n",
    "mov_cat_feat = mov_cat_fc(mov_cat_feat)\n",
    "mov_cat_feat = F.relu(mov_cat_feat)\n",
    "print(mov_cat_feat.shape)\n",
    "print(mov_cat_feat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 提取电影名称特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影名称输入数据形状： torch.Size([2, 1, 15])\n",
      "经过Embedding层后的形状： torch.Size([2, 1, 15, 32])\n",
      "经过第一层卷积后的形状： torch.Size([2, 1, 7, 32])\n",
      "经过第二层卷积后的形状： torch.Size([2, 1, 5, 32])\n",
      "经过reduce_sum降采样后： torch.Size([2, 1, 32])\n",
      "torch.Size([2, 32])\n"
     ]
    }
   ],
   "source": [
    "# 自定义电影名称数据\n",
    "mov_tit_data = np.array([[1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                         [2, 3, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).reshape(2, 1, -1).astype('int64')\n",
    "mov_tit_dict_size = 5216 + 1\n",
    "mov_tit_emb = nn.Embedding(num_embeddings=mov_tit_dict_size, embedding_dim=32)\n",
    "mov_tit_conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 1), stride=(2, 1))\n",
    "mov_tit_conv2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(3, 1))\n",
    "\n",
    "mov_tit_var = torch.from_numpy(mov_tit_data)\n",
    "print('电影名称输入数据形状：', mov_tit_var.shape)\n",
    "\n",
    "mov_tit_feat = mov_tit_emb(mov_tit_var)\n",
    "print('经过Embedding层后的形状：', mov_tit_feat.shape)\n",
    "\n",
    "mov_tit_feat = mov_tit_conv(mov_tit_feat)\n",
    "print('经过第一层卷积后的形状：', mov_tit_feat.shape)\n",
    "\n",
    "mov_tit_feat = mov_tit_conv2(mov_tit_feat)\n",
    "print('经过第二层卷积后的形状：', mov_tit_feat.shape)\n",
    "\n",
    "batch_size = mov_tit_feat.shape[0]\n",
    "mov_tit_feat = torch.sum(mov_tit_feat, dim=2, keepdim=False)\n",
    "print('经过reduce_sum降采样后：', mov_tit_feat.shape)\n",
    "\n",
    "mov_tit_feat = F.relu(mov_tit_feat)\n",
    "mov_tit_feat = mov_tit_feat.reshape(batch_size, -1)\n",
    "print(mov_tit_feat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 电影海报特征提取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "poster1 = Image.open('./data/posters/mov_id2294.jpg').resize((64, 64))\n",
    "poster2 = Image.open('./data/posters/mov_id2299.jpg').resize((64, 64))\n",
    "\n",
    "# h, w, c -> c, h, w\n",
    "poster1_data = np.array(poster1).transpose((2, 0, 1))\n",
    "poster1_data = poster1_data/127.5 - 1\n",
    "poster2_data = np.array(poster2).transpose((2, 0, 1))\n",
    "poster2_data = poster2_data/127.5 - 1\n",
    "\n",
    "posters_data = np.array([poster1_data, poster2_data]).astype('float')\n",
    "\n",
    "poster_conv = nn.Sequential(\n",
    "    # (2, 3, 64, 64) -> (2, 32, 32, 32)\n",
    "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # (2, 32, 32, 32) -> (2, 32, 16, 16)\n",
    "    nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # (2, 32, 16, 16) -> (2, 64, 8, 8)\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    # (2, 64, 8, 8) -> (2, 64, 1, 1)\n",
    "    nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    ")\n",
    "poster_fc = nn.Linear(in_features=64, out_features=32)\n",
    "\n",
    "posters_var = torch.from_numpy(posters_data).float()\n",
    "posters_feat = poster_conv(posters_var)\n",
    "batch_size = posters_feat.shape[0]\n",
    "posters_feat = posters_feat.reshape(batch_size, -1)\n",
    "posters_feat = poster_fc(posters_feat)\n",
    "print(posters_feat.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 融合电影特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 200])\n"
     ]
    }
   ],
   "source": [
    "mov_combined = nn.Linear(in_features=96, out_features=200)\n",
    "\n",
    "mov_feats = [mov_cat_feat, mov_tit_feat, posters_feat]\n",
    "mov_feats = torch.cat(mov_feats, dim=1)\n",
    "mov_feats = mov_combined(mov_feats)\n",
    "print(mov_feats.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 相似度计算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1667, 0.1522], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def similarty(usr_feature, mov_feature):\n",
    "    res = F.cosine_similarity(usr_feature, mov_feature)\n",
    "    res = 5 * res\n",
    "    return res\n",
    "\n",
    "_sim = similarty(usr_feat, mov_feats)\n",
    "print(_sim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "rs",
   "language": "python",
   "display_name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}